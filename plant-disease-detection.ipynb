{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":658267,"datasetId":277323}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Import libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\nimport tensorflow as tf\nfrom tensorflow import keras\n","metadata":{"id":"bYWb1UN6sqmv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Read dataset**","metadata":{}},{"cell_type":"code","source":"path = '../input/plantvillage-dataset/color'\ntrain_ds , test_ds = keras.utils.image_dataset_from_directory(\n    path ,\n    image_size=(224,224),\n    batch_size=32 ,\n    seed = 123 ,\n    validation_split=.2,\n    subset='both'\n)\n","metadata":{"id":"o1_5m8oKtfdr","outputId":"b9ac1b16-8b9e-4abf-c51a-236c7ea66ed0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = train_ds.class_names\nclasses","metadata":{"id":"XxAu9N1BJYx5","outputId":"3070539b-f557-4a4a-cd31-d6995ef2da30","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Visualize Some Images**","metadata":{}},{"cell_type":"code","source":"image = cv2.imread(\"../input/plantvillage-dataset/color/Apple___Apple_scab/01f3deaa-6143-4b6c-9c22-620a46d8be04___FREC_Scab 3112.JPG\")\nplt.figure(figsize = (6,6))\nplt.imshow(image)\nplt.title('Apple scab',size =18 )\nplt.axis('off')\nplt.show()","metadata":{"id":"JbTwSo3MwakU","outputId":"7ead59ae-410e-4847-902a-cc13ea74a6d3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----------------------------------","metadata":{"id":"jvyKLGhh5g8d"}},{"cell_type":"code","source":"image = cv2.imread(\"../input/plantvillage-dataset/color/Peach___Bacterial_spot/00e6ad4a-5a62-48d7-ac68-9c0b8ec87f5f___Rut._Bact.S 1472.JPG\")\nplt.figure(figsize = (6,6))\nplt.imshow(image)\nplt.title('Peach Bacterial spot',size =18 )\nplt.axis('off')\nplt.show()","metadata":{"id":"QZq--IqN1d4N","outputId":"7d50cbf2-8c77-45e2-9baf-95840e703027","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-----------------------------","metadata":{"id":"M2mJ2Mh57l5S"}},{"cell_type":"code","source":"image = cv2.imread(\"../input/plantvillage-dataset/color/Tomato___Septoria_leaf_spot/015c2613-fb1c-4f31-88f1-c7e5be9ddc97___JR_Sept.L.S 8431.JPG\")\nplt.figure(figsize = (6,6))\nplt.imshow(image)\nplt.title('Tomato Septoria leaf spot',size =18 )\nplt.axis('off')\nplt.show()","metadata":{"id":"jvsR4EJL7YJX","outputId":"09fc65d4-8cc3-45fa-8ef1-bffd768342a3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Build Neural network [CNN]**","metadata":{}},{"cell_type":"code","source":"\nmodel = keras.Sequential([\n    keras.layers.Rescaling(scale = 1/255 , input_shape =(224,224,3) ) ,\n\n    keras.layers.Conv2D(32 , (3,3) , activation = 'relu'),\n    keras.layers.MaxPool2D((2,2))                     ,\n    keras.layers.Dropout(0.2),\n\n    keras.layers.Conv2D(64 , (3,3) , activation = 'relu') ,\n    keras.layers.MaxPool2D((2,2)) ,\n    keras.layers.Dropout(0.2),\n\n    keras.layers.Conv2D(64 , (3,3) , activation = 'relu') ,\n    keras.layers.MaxPool2D((2,2)) ,\n    keras.layers.Dropout(0.2),\n\n    keras.layers.Conv2D(64 , (3,3) , activation = 'relu') ,\n    keras.layers.MaxPool2D((2,2)) ,\n    keras.layers.Dropout(0.2),\n\n    keras.layers.Conv2D(128 , (3,3) , activation = 'relu') ,\n    keras.layers.MaxPool2D((2,2)) ,\n\n    # fully connected layers\n\n    keras.layers.Flatten(),\n    keras.layers.Dense(128,activation = 'relu'),\n    keras.layers.Dense(64,activation = 'relu'),\n    keras.layers.Dense(38,activation ='sigmoid')\n\n])","metadata":{"id":"mWDyIIim759m","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer = 'adam' ,\n    loss = 'sparse_categorical_crossentropy',\n    metrics = 'accuracy'\n)","metadata":{"id":"WTYsb0uk_qCW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"id":"je77DVU5yqNf","outputId":"22d954f1-90c4-47d8-c9d5-1429e37657f1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Trai model**","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_ds , epochs = 20)","metadata":{"id":"Hbdz2Ql2AWvW","outputId":"009725eb-418e-402d-953e-8b36dd923183","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = history.history['accuracy']\nloss = history.history['loss']\nepochs = range(1,21)\n\nplt.plot(epochs , accuracy , label = 'Acuuracy')\nplt.plot(epochs , loss , label = 'loss')\nplt.legend()\nplt.show()","metadata":{"id":"eVjBq-t39sKN","outputId":"710fc48b-fd59-45d2-bce2-765612864105","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_ds)","metadata":{"id":"CIv4ni9lAgun","outputId":"ba5e27b9-f8ab-4536-df39-ecc514fe4794","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Test model predictions**","metadata":{}},{"cell_type":"code","source":"def img_to_pred(image):\n  image = image.numpy()\n  image = tf.expand_dims(image,0)\n  return image","metadata":{"id":"fv0r6C0-HiqS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18,18))\nfor images, labels in test_ds.take(1) : # take the first patch\n  for i in range(1,10):\n    plt.subplot(3,3,i)\n    plt.imshow(images[i].numpy().astype('uint32'))\n    plt.axis('off')\n    actual = classes[labels[i]]\n    predict =classes[np.argmax( model.predict(img_to_pred(images[i])))]\n    plt.title(f\"actual : {actual}  \\n predicted : {predict} \")","metadata":{"id":"xALcpafMby8r","outputId":"2e9db472-c3ef-4367-a6ae-af642126eceb","trusted":true},"execution_count":null,"outputs":[]}]}